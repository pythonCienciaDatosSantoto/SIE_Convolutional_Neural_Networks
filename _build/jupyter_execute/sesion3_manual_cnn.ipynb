{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs desde Cero - Operaciones y Entrenamiento\n",
    "\n",
    "**Objetivo:** En este notebook especial, vamos a desmitificar por completo las Redes Neuronales Convolucionales. Dejaremos de lado TensorFlow y construiremos las operaciones fundamentales desde cero usando únicamente NumPy. \n",
    "\n",
    "1.  **Parte 1:** Ilustraremos el `forward pass` de una única capa convolucional para entender mecánicamente cómo funcionan el padding, la convolución, la activación y el pooling.\n",
    "2.  **Parte 2:** Simularemos el entrenamiento de una mini-CNN completa para ver cómo la red puede *aprender* los filtros correctos a través de la retropropagación y el descenso de gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Anatomía de una Capa Convolucional (Forward Pass)\n",
    "\n",
    "En esta primera parte, nos enfocamos en visualizar qué ocurre dentro de una capa `Conv2D` cuando procesa una imagen. La siguiente clase, `CapaConvolucionalManual`, implementa cada paso de forma explícita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapaConvolucionalManual:\n",
    "    \"\"\"\n",
    "    Una clase para demostrar el funcionamiento de una capa convolucional\n",
    "    y de pooling desde cero, utilizando únicamente NumPy.\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel, stride=1, padding=0, pool_size=2, pool_stride=2):\n",
    "        \"\"\"\n",
    "        Inicializa la capa con sus hiperparámetros.\n",
    "\n",
    "        :param kernel: El filtro (o kernel) a aplicar. Debe ser un array 2D de NumPy.\n",
    "        :type kernel: np.ndarray\n",
    "        :param stride: El paso (stride) del filtro al convolucionar.\n",
    "        :type stride: int\n",
    "        :param padding: El ancho del relleno (padding) a añadir a la imagen.\n",
    "        :type padding: int\n",
    "        :param pool_size: El tamaño de la ventana de pooling (ej. 2 para una ventana de 2x2).\n",
    "        :type pool_size: int\n",
    "        :param pool_stride: El paso (stride) de la ventana de pooling.\n",
    "        :type pool_stride: int\n",
    "        \"\"\"\n",
    "        self.kernel = kernel\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.pool_size = pool_size\n",
    "        self.pool_stride = pool_stride\n",
    "        print(\"Capa inicializada con éxito.\")\n",
    "        print(f\"Kernel (Filtro):\\n{self.kernel}\")\n",
    "        print(f\"Stride: {self.stride}, Padding: {self.padding}\")\n",
    "        print(f\"Tamaño de Pooling: {self.pool_size}, Stride de Pooling: {self.pool_stride}\\n\")\n",
    "\n",
    "    def _aplicar_padding(self, imagen):\n",
    "        if self.padding == 0:\n",
    "            return imagen\n",
    "        return np.pad(imagen, pad_width=self.padding, mode='constant', constant_values=0)\n",
    "\n",
    "    def _operacion_convolucion(self, region_imagen):\n",
    "        producto = self.kernel * region_imagen\n",
    "        return np.sum(producto)\n",
    "\n",
    "    def convolucionar(self, imagen_padded):\n",
    "        alto_kernel, ancho_kernel = self.kernel.shape\n",
    "        alto_imagen, ancho_imagen = imagen_padded.shape\n",
    "        alto_salida = (alto_imagen - alto_kernel) // self.stride + 1\n",
    "        ancho_salida = (ancho_imagen - ancho_kernel) // self.stride + 1\n",
    "        feature_map = np.zeros((alto_salida, ancho_salida))\n",
    "        for y in range(0, alto_salida):\n",
    "            for x in range(0, ancho_salida):\n",
    "                y_inicio = y * self.stride\n",
    "                x_inicio = x * self.stride\n",
    "                region = imagen_padded[y_inicio : y_inicio + alto_kernel, x_inicio : x_inicio + ancho_kernel]\n",
    "                feature_map[y, x] = self._operacion_convolucion(region)\n",
    "        return feature_map\n",
    "\n",
    "    def _relu(self, feature_map):\n",
    "        return np.maximum(0, feature_map)\n",
    "\n",
    "    def _max_pooling(self, feature_map_activado):\n",
    "        alto_mapa, ancho_mapa = feature_map_activado.shape\n",
    "        alto_salida = (alto_mapa - self.pool_size) // self.pool_stride + 1\n",
    "        ancho_salida = (ancho_mapa - self.pool_size) // self.pool_stride + 1\n",
    "        pooled_map = np.zeros((alto_salida, ancho_salida))\n",
    "        for y in range(0, alto_salida):\n",
    "            for x in range(0, ancho_salida):\n",
    "                y_inicio = y * self.pool_stride\n",
    "                x_inicio = x * self.pool_stride\n",
    "                region = feature_map_activado[y_inicio : y_inicio + self.pool_size, x_inicio : x_inicio + self.pool_size]\n",
    "                pooled_map[y, x] = np.max(region)\n",
    "        return pooled_map\n",
    "\n",
    "    def forward_pass(self, imagen):\n",
    "        print(\"--- INICIANDO FORWARD PASS ---\")\n",
    "        print(\"1. Aplicando Padding...\")\n",
    "        imagen_padded = self._aplicar_padding(imagen)\n",
    "        print(f\"Imagen Original:\\n{imagen}\")\n",
    "        print(f\"Imagen con Padding (tamaño {self.padding}):\\n{imagen_padded}\\n\")\n",
    "        print(\"2. Aplicando Convolución...\")\n",
    "        feature_map = self.convolucionar(imagen_padded)\n",
    "        print(f\"Mapa de Características (Feature Map) resultante:\\n{feature_map}\\n\")\n",
    "        print(\"3. Aplicando Activación ReLU...\")\n",
    "        feature_map_activado = self._relu(feature_map)\n",
    "        print(f\"Mapa de Características Activado (valores negativos a 0):\\n{feature_map_activado}\\n\")\n",
    "        print(\"4. Aplicando Max Pooling...\")\n",
    "        pooled_map = self._max_pooling(feature_map_activado)\n",
    "        print(f\"Mapa de Características Final (después de Pooling):\\n{pooled_map}\\n\")\n",
    "        print(\"--- FORWARD PASS COMPLETADO ---\")\n",
    "        return pooled_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### DEMOSTRACIÓN DE LA CAPA CONVOLUCIONAL MANUAL ###\n",
      "\n",
      "Capa inicializada con éxito.\n",
      "Kernel (Filtro):\n",
      "[[ 1  0 -1]\n",
      " [ 1  0 -1]\n",
      " [ 1  0 -1]]\n",
      "Stride: 1, Padding: 1\n",
      "Tamaño de Pooling: 2, Stride de Pooling: 2\n",
      "\n",
      "--- INICIANDO FORWARD PASS ---\n",
      "1. Aplicando Padding...\n",
      "Imagen Original:\n",
      "[[10 10 10  0  0]\n",
      " [10 10 10  0  0]\n",
      " [10 10 10  0  0]\n",
      " [ 0  0  0 10 10]\n",
      " [ 0  0  0 10 10]]\n",
      "Imagen con Padding (tamaño 1):\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0 10 10 10  0  0  0]\n",
      " [ 0 10 10 10  0  0  0]\n",
      " [ 0 10 10 10  0  0  0]\n",
      " [ 0  0  0  0 10 10  0]\n",
      " [ 0  0  0  0 10 10  0]\n",
      " [ 0  0  0  0  0  0  0]]\n",
      "\n",
      "2. Aplicando Convolución...\n",
      "Mapa de Características (Feature Map) resultante:\n",
      "[[-20.   0.  20.  20.   0.]\n",
      " [-30.   0.  30.  30.   0.]\n",
      " [-20.   0.  10.  10.  10.]\n",
      " [-10.   0. -10. -10.  20.]\n",
      " [  0.   0. -20. -20.  20.]]\n",
      "\n",
      "3. Aplicando Activación ReLU...\n",
      "Mapa de Características Activado (valores negativos a 0):\n",
      "[[ 0.  0. 20. 20.  0.]\n",
      " [ 0.  0. 30. 30.  0.]\n",
      " [ 0.  0. 10. 10. 10.]\n",
      " [ 0.  0.  0.  0. 20.]\n",
      " [ 0.  0.  0.  0. 20.]]\n",
      "\n",
      "4. Aplicando Max Pooling...\n",
      "Mapa de Características Final (después de Pooling):\n",
      "[[ 0. 30.]\n",
      " [ 0. 10.]]\n",
      "\n",
      "--- FORWARD PASS COMPLETADO ---\n"
     ]
    }
   ],
   "source": [
    "# --- Ejecución de la Parte 1 ---\n",
    "print(\"### DEMOSTRACIÓN DE LA CAPA CONVOLUCIONAL MANUAL ###\\n\")\n",
    "imagen_ejemplo = np.array([\n",
    "    [10, 10, 10,  0,  0],\n",
    "    [10, 10, 10,  0,  0],\n",
    "    [10, 10, 10,  0,  0],\n",
    "    [ 0,  0,  0, 10, 10],\n",
    "    [ 0,  0,  0, 10, 10]\n",
    "])\n",
    "\n",
    "filtro_ejemplo = np.array([\n",
    "    [ 1,  0, -1],\n",
    "    [ 1,  0, -1],\n",
    "    [ 1,  0, -1]\n",
    "])\n",
    "\n",
    "capa_cnn = CapaConvolucionalManual(kernel=filtro_ejemplo, stride=1, padding=1, pool_size=2, pool_stride=2)\n",
    "resultado_final = capa_cnn.forward_pass(imagen_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Entrenamiento de una Mini-CNN Completa\n",
    "\n",
    "Ahora que entendemos las operaciones, vamos a unirlas en una red completa y a simular cómo \"aprende\". Crearemos un dataset sintético donde el objetivo es clasificar si una imagen contiene una línea vertical u horizontal. Veremos cómo la red, partiendo de un filtro aleatorio, ajusta sus pesos para resolver la tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_dataset(n_muestras):\n",
    "    \"\"\"\n",
    "    Genera un dataset sintético de imágenes 5x5.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(n_muestras):\n",
    "        imagen = np.zeros((5, 5))\n",
    "        if i % 2 == 0:\n",
    "            # Línea vertical (target = 1)\n",
    "            imagen[:, 2] = 1\n",
    "            y.append(1)\n",
    "        else:\n",
    "            # Línea horizontal (target = 0)\n",
    "            imagen[2, :] = 1\n",
    "            y.append(0)\n",
    "        imagen += np.random.rand(5, 5) * 0.2\n",
    "        X.append(imagen)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniCNNManual:\n",
    "    \"\"\"\n",
    "    Una clase que simula una CNN completa con una capa convolucional,\n",
    "    pooling, y una capa densa para clasificación binaria.\n",
    "    Implementa el entrenamiento desde cero.\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        self.kernel = np.random.randn(3, 3) * 0.1\n",
    "        self.dense_weights = np.random.randn(4, 1) * 0.1\n",
    "        self.dense_bias = np.random.randn(1, 1) * 0.1\n",
    "        self.lr = learning_rate\n",
    "        print(\"Mini-CNN inicializada.\")\n",
    "        print(f\"Kernel inicial (aleatorio):\\n{self.kernel}\")\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def _binary_cross_entropy_loss(self, y_true, y_pred):\n",
    "        return - (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "    def forward(self, imagen):\n",
    "        conv_output = np.zeros((3, 3))\n",
    "        for y in range(3):\n",
    "            for x in range(3):\n",
    "                region = imagen[y:y+3, x:x+3]\n",
    "                conv_output[y, x] = np.sum(region * self.kernel)\n",
    "        relu_output = self._relu(conv_output)\n",
    "        pool_output = np.zeros((2, 2))\n",
    "        for y in range(2):\n",
    "            for x in range(2):\n",
    "                region = relu_output[y:y+2, x:x+2]\n",
    "                pool_output[y, x] = np.max(region)\n",
    "        flattened_output = pool_output.flatten().reshape(1, -1)\n",
    "        dense_input = flattened_output\n",
    "        dense_output = dense_input @ self.dense_weights + self.dense_bias\n",
    "        prediction = self._sigmoid(dense_output)\n",
    "        cache = {\n",
    "            \"imagen\": imagen, \"conv_output\": conv_output, \"relu_output\": relu_output,\n",
    "            \"pool_output\": pool_output, \"dense_input\": dense_input, \"prediction\": prediction\n",
    "        }\n",
    "        return prediction, cache\n",
    "\n",
    "    def backward(self, y_true, cache):\n",
    "        d_loss_d_pred = - (y_true / cache[\"prediction\"] - (1 - y_true) / (1 - cache[\"prediction\"]))\n",
    "        d_pred_d_dense = cache[\"prediction\"] * (1 - cache[\"prediction\"])\n",
    "        d_loss_d_dense = d_loss_d_pred * d_pred_d_dense\n",
    "        self.grad_dense_weights = cache[\"dense_input\"].T @ d_loss_d_dense\n",
    "        self.grad_dense_bias = np.sum(d_loss_d_dense, axis=0, keepdims=True)\n",
    "        d_loss_d_flatten = d_loss_d_dense @ self.dense_weights.T\n",
    "        d_loss_d_pool = d_loss_d_flatten.reshape(cache[\"pool_output\"].shape)\n",
    "        d_loss_d_relu = np.zeros(cache[\"relu_output\"].shape)\n",
    "        for y in range(2):\n",
    "            for x in range(2):\n",
    "                region = cache[\"relu_output\"][y:y+2, x:x+2]\n",
    "                max_val = np.max(region)\n",
    "                mask = (region == max_val)\n",
    "                d_loss_d_relu[y:y+2, x:x+2] += d_loss_d_pool[y,x] * mask\n",
    "        d_relu_d_conv = cache[\"relu_output\"] > 0\n",
    "        d_loss_d_conv = d_loss_d_relu * d_relu_d_conv\n",
    "        self.grad_kernel = np.zeros(self.kernel.shape)\n",
    "        for y in range(3):\n",
    "            for x in range(3):\n",
    "                region = cache[\"imagen\"][y:y+3, x:x+3]\n",
    "                self.grad_kernel += region * d_loss_d_conv[y, x]\n",
    "\n",
    "    def train(self, X, y, epochs):\n",
    "        print(\"\\n--- INICIANDO ENTRENAMIENTO ---\")\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for imagen, etiqueta in zip(X, y):\n",
    "                prediccion, cache = self.forward(imagen)\n",
    "                total_loss += self._binary_cross_entropy_loss(etiqueta, prediccion)\n",
    "                self.backward(etiqueta, cache)\n",
    "                self.kernel -= self.lr * self.grad_kernel\n",
    "                self.dense_weights -= self.lr * self.grad_dense_weights\n",
    "                self.dense_bias -= self.lr * self.grad_dense_bias\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                avg_loss = total_loss / len(X)\n",
    "                print(f\"Época {epoch+1}/{epochs}, Pérdida Promedio: {avg_loss[0][0]:.4f}\")\n",
    "        print(\"--- ENTRENAMIENTO COMPLETADO ---\")\n",
    "        print(f\"Kernel final (aprendido):\\n{self.kernel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### SIMULACIÓN DE ENTRENAMIENTO DE MINI-CNN ###\n",
      "\n",
      "Mini-CNN inicializada.\n",
      "Kernel inicial (aleatorio):\n",
      "[[-0.02355612  0.00804416  0.03578015]\n",
      " [ 0.05786005 -0.01891272 -0.03601907]\n",
      " [-0.05485257  0.01644713  0.09190044]]\n",
      "\n",
      "--- INICIANDO ENTRENAMIENTO ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 10/50, Pérdida Promedio: 0.2841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 20/50, Pérdida Promedio: 0.0348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 30/50, Pérdida Promedio: 0.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 40/50, Pérdida Promedio: 0.0060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 50/50, Pérdida Promedio: 0.0039\n",
      "--- ENTRENAMIENTO COMPLETADO ---\n",
      "Kernel final (aprendido):\n",
      "[[-0.60901178  0.76119948 -0.55159816]\n",
      " [-0.50227857  0.73741483 -0.6180919 ]\n",
      " [ 0.41475851  1.85295713  0.57305541]]\n",
      "\n",
      "--- PROBANDO MODELO ENTRENADO ---\n",
      "\n",
      "Imagen de prueba (Línea Vertical):\n",
      "[[0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n",
      "Predicción (debería ser cercano a 1): 0.9955\n",
      "\n",
      "Imagen de prueba (Línea Horizontal):\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "Predicción (debería ser cercano a 0): 0.0066\n"
     ]
    }
   ],
   "source": [
    "# --- Ejecución de la Parte 2 ---\n",
    "print(\"\\n### SIMULACIÓN DE ENTRENAMIENTO DE MINI-CNN ###\\n\")\n",
    "X_train, y_train = generar_dataset(100)\n",
    "cnn = MiniCNNManual(learning_rate=0.01)\n",
    "cnn.train(X_train, y_train, epochs=50)\n",
    "\n",
    "print(\"\\n--- PROBANDO MODELO ENTRENADO ---\")\n",
    "test_vertical = np.zeros((5,5))\n",
    "test_vertical[:, 2] = 1\n",
    "\n",
    "test_horizontal = np.zeros((5,5))\n",
    "test_horizontal[2, :] = 1\n",
    "\n",
    "pred_v, _ = cnn.forward(test_vertical)\n",
    "pred_h, _ = cnn.forward(test_horizontal)\n",
    "\n",
    "print(f\"\\nImagen de prueba (Línea Vertical):\\n{test_vertical}\")\n",
    "print(f\"Predicción (debería ser cercano a 1): {pred_v[0][0]:.4f}\")\n",
    "\n",
    "print(f\"\\nImagen de prueba (Línea Horizontal):\\n{test_horizontal}\")\n",
    "print(f\"Predicción (debería ser cercano a 0): {pred_h[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión del Notebook\n",
    "\n",
    "En este notebook hemos construido una CNN desde sus cimientos. Vimos cómo las operaciones matemáticas de convolución y pooling transforman una imagen, y lo más importante, cómo el proceso de entrenamiento (forward y backward pass) permite a la red **aprender** los valores correctos para sus filtros, especializándose en la tarea que le hemos asignado. Este entendimiento fundamental es clave para usar eficazmente las librerías de alto nivel como TensorFlow y Keras."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}